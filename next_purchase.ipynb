{"cells":[{"cell_type":"code","source":["#import the dataset\ndata = spark.read.csv(\"dbfs:/FileStore/tables/automotive_sales-1.csv\", inferSchema = True, header = True, sep = \",\").cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92f42ef6-5418-4fc9-b33b-fde8f9369da6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#check the data type of each feature\ndata.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5be46d7-0913-466c-b5f1-4bce7fe7292d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- cust: integer (nullable = true)\n |-- creditorcash: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- product: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- purchase_date: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- cust: integer (nullable = true)\n-- creditorcash: string (nullable = true)\n-- gender: string (nullable = true)\n-- product: string (nullable = true)\n-- age: integer (nullable = true)\n-- purchase_date: string (nullable = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#change the new_purchase_date in case it's not date type yet\nfrom pyspark.sql.functions import unix_timestamp, from_unixtime, to_date\ndata = data.withColumn('new_purchase_date', to_date(unix_timestamp('purchase_date', 'yyyy/MM/dd').cast(\"timestamp\"))).drop('purchase_date')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c116174f-b1cd-4d55-8160-e92d4d499026"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#sort by cust and purchase date\ndata = data.orderBy([\"cust\", \"new_purchase_date\"], ascending=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c12cda98-bd45-41af-9dcb-02815551b2bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#calculating the days interval between purchases for each customer which will be our target variable\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window\ndata = data.withColumn(\"timeInterval\", datediff(data.new_purchase_date, lag(data.new_purchase_date, 1)\n    .over(Window.partitionBy(\"cust\")\n    .orderBy(\"new_purchase_date\"))))\ndata = data.na.fill({'timeInterval': 0})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"921434c9-4b5b-4ec1-a6e4-0c1c58aa209e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#create flag of the i-th number of purchase (1st time, 2nd time, etc.) as a new feature\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import rank, dense_rank\nfrom pyspark.sql.functions import unix_timestamp, from_unixtime, to_date\n\nwindow = Window.partitionBy(data['cust']).orderBy(data['new_purchase_date'])\ndata = data.select('*', rank().over(window).alias('flag'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01aeef76-4ca0-471f-a216-17f326e6e975"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#evaluate the correlation of numerical features with the target variable\nimport six\n\ncorr_cols = [\"age\"]\nfor i in corr_cols:\n    if not( isinstance(data.select(i).take(1)[0][0], six.string_types)):\n        print( \"Correlation to timeInterval for \", i, data.stat.corr('timeInterval',i))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4b50bd5-8711-4a71-9d3b-8fc164fe4074"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Correlation to timeInterval for  age 0.24728588474479177\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Correlation to timeInterval for  age 0.24728588474479177\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder\nstages = []\ncat_cols = [\"gender\", \"product\", \"flag\"]\n\nfor cat_col in cat_cols:\n  indexer = StringIndexer(inputCol = cat_col, outputCol = cat_col + \"_index\", stringOrderType = \"alphabetAsc\")\n  encoder = OneHotEncoder(inputCols = [indexer.getOutputCol()], outputCols = [cat_col + \"_vec\"], dropLast = True)\n  stages += [indexer, encoder]\n  \npipeline = Pipeline(stages=stages)\ndata2 = pipeline.fit(data).transform(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45c71abf-234f-43f5-a229-774405c97267"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#split the date into training and testing with set up seed for consistency\n(train, test) = data2.randomSplit([0.8, 0.2], seed=123)\ntrain.cache()\ntest.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd2ad2e0-29c2-45be-bac2-d8b286a3f7c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[12]: DataFrame[cust: int, creditorcash: string, gender: string, product: string, age: int, new_purchase_date: date, timeInterval: int, flag: int, gender_index: double, gender_vec: vector, product_index: double, product_vec: vector, flag_index: double, flag_vec: vector]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: DataFrame[cust: int, creditorcash: string, gender: string, product: string, age: int, new_purchase_date: date, timeInterval: int, flag: int, gender_index: double, gender_vec: vector, product_index: double, product_vec: vector, flag_index: double, flag_vec: vector]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# TODO: Build a better Regression pipeline\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.feature import VectorAssembler\n\nassemblerInputs = [\"gender_vec\", \"product_vec\", \"flag_vec\", \"age\"]\n\nvectorAssembler = VectorAssembler(\n  inputCols = assemblerInputs, \n  outputCol=\"features\")\n\nrfr = (RandomForestRegressor()\n      .setLabelCol(\"timeInterval\") # The column of our label\n      .setSeed(123)        # Some seed value for consistency\n      .setNumTrees(10)   # A guess at the number of trees\n      .setMaxDepth(30)    # A guess at the depth of each tree\n)\n\npipelinerfr = Pipeline().setStages([\n  vectorAssembler,\n  rfr\n])\n\npipelineModelrfr = pipelinerfr.fit(train)\n\npredictionsDFrfr = pipelineModelrfr.transform(test)\n\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator().setLabelCol(\"timeInterval\")\n\nrmserfr = evaluator.evaluate(predictionsDFrfr)\n\nprint(\"Test RMSE Random Forest Regressor = %f\" % rmserfr)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bad064a-07c6-4cad-be9c-512ec08d547a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Test RMSE Random Forest Regressor = 240.711339\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test RMSE Random Forest Regressor = 240.711339\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#compare the RMSE with the average to get the sense of how well the model works as a simple analysis\nfrom pyspark.sql.functions import col, avg\ndata.agg(avg(col(\"timeInterval\"))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"416d6e17-ded0-4859-af58-ea036af8d11d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------+\n|avg(timeInterval)|\n+-----------------+\n|           773.08|\n+-----------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+\navg(timeInterval)|\n+-----------------+\n           773.08|\n+-----------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"382f647a-b42c-493e-bc2a-48c07d19c51a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"next_purchase","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4172385630532999}},"nbformat":4,"nbformat_minor":0}
